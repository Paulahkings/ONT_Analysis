{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EANBiT Residential Training 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to the data\n",
    "[This](https://www.dropbox.com/s/nkyunpxtwa4s0td/recov_data.zip?dl=0) is the link to the fast5 files we will use for this training.\n",
    "\n",
    "\n",
    "[This](https://drive.google.com/file/d/1Jyf_yMIhor7NnqhbIfBJSBlRTuKvJvhx/view?usp=sharing) is the link to the basecalled fastq files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bash-kernel in c:\\users\\secondfiddle\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: pexpect>=4.0 in c:\\users\\secondfiddle\\anaconda3\\lib\\site-packages (from bash-kernel) (4.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in c:\\users\\secondfiddle\\anaconda3\\lib\\site-packages (from pexpect>=4.0->bash-kernel) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "#Install bash kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install bash-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available kernels:\n",
      "  python3    C:\\Users\\SecondFiddle\\Anaconda3\\share\\jupyter\\kernels\\python3\n"
     ]
    }
   ],
   "source": [
    "#jupyter console --kernel bash\n",
    "!jupyter kernelspec list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing fast5 files using Bulkvis\n",
    "BulkVis is a program written in Python3 using Bokeh to visualise raw squiggle data from Oxford Nanopore Technologies (ONT) bulkfiles. [Bulkvis](https://github.com/LooseLab/bulkvis) scans a folder containing bulk FAST5 files at startup. An individual file is selected and specific channels plotted. Basic metadata are displayed to the user. To navigate coordinates are input in the format `channel: start_time-end_time`. Alternatively pasting a FASTQ read header from a base called read will jump to its channel, time and raw signal from the bulk FAST5 file (Payne et al., 2019). Further information on how to strt bulkvis can be found [here](https://bulkvis.readthedocs.io/en/latest/quickstart.html).\n",
    "\n",
    "Before you install bulkvis, make sure you have pip installed.\n",
    "To check whether you have pip installed, run this command:\n",
    "\n",
    "`pip --version`\n",
    "\n",
    "If pip is not installed, no worries! Let's fix that.\n",
    "Let's get on with the installation.\n",
    "To install pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## On Debian/Ubuntu\n",
    "apt install python3-pip\n",
    "## On CentOS\n",
    "yum install epel-release \n",
    "yum install python-pip\n",
    "## Using conda \n",
    "conda install -c anaconda pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have `pip` installed, you will be required to create and activate a virtual environment to work on.\n",
    "To do this, follow [these](https://bulkvis.readthedocs.io/en/latest/installation.html) simple instructions. Please edit the paths to match yours where need be, and make sure you are using the **bulk fast5 file** not a single fast5 file. This bulk fast 5 file is obtained by setting up the sequencing run as shown [here](https://github.com/LooseLab/bulkvis/issues/28) on MinKNOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basecalling\n",
    "fast5 files generated from the sequencing step are basecalled\n",
    "##### Basecalling script\n",
    "This script was developed by [Sirselim](https://gist.github.com/sirselim) for faster basecalling with the free GPU resources on [Google collaboratory](https://research.google.com/colaboratory/). If you would like to try out/use this resource, please use your google account to open google collaboratory, and  create a notebook of your own to implement the script below.\n",
    "\n",
    "[This](https://gist.github.com/sirselim/13f70ae69f2a512e7d9e1f00f9704f53) is the link to his basecalling script on his github page. However, there is an alternative to use CPU resources, whose basecalling capabilities are way slower.\n",
    "\n",
    "Alternatively, we can perform CPU basecalling as shown below. It is recommended you run this step on the HPC where more threads can be allocated per caller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remotely sign into your HPC using your ssh address: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssh <username>@host.address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guppy can be installed using the code shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "#Install Guppy\n",
    "GuppyBinary=(\"https://mirror.oxfordnanoportal.com/software/analysis/ont-guppy_5.0.11_linux64.tar.gz\")\n",
    "wget $GuppyBinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpack the guppy binary files using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "tar -xvzf ont-guppy_5.0.11_linux64.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the basecalling step you need to know the [flowcell and ONT kit](https://denbi-nanopore-training-course.readthedocs.io/en/latest/basecalling/basecalling.html) used to generate your fast5 files. In this case the kit used was SQK-PCB109, and FLO-MIN106 flowcell. The config file used for this combination is:\n",
    "**dna_r9.4.1_450bps_hac**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guppy_basecaller --compress_fastq -i ~/workdir/data/fast5_tiny/ \\\n",
    "-s ~/workdir/basecall_tiny/ --cpu_threads_per_caller 14 --num_callers 1 -c dna_r9.4.1_450bps_hac.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you encounter a `libzmq.so.5` error go [here](https://github.com/bulwark-crypto/Bulwark/issues/28) and use the code chunk to recompile zeromq library "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the script [ONT_analysis.sh](https://github.com/eKariuki-sleepy/ONT_Analysis/blob/main/ONT_analysis.sh) for basecalling. Please edit the variables accordingly to suit your directory structure. The exercise will take approximately 25 minutes running on 16 threads and one-caller. [This](https://denbi-nanopore-training-course.readthedocs.io/en/latest/basecalling/basecalling.html) resource provides more information about basecalling with guppy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain Quality statistics with pycoQC\n",
    "[PycoQC](https://github.com/tleonardi/pycoQC) computes metrics and generates interactive QC plots for Oxford Nanopore technologies sequencing data.\n",
    "\n",
    "PycoQC relies on the sequencing_summary.txt file generated by Albacore and Guppy (hence limited input options), but if needed it can also generate a summary file from basecalled fast5 files. The package supports 1D and 1D2 runs generated with Minion, Gridion and Promethion devices, basecalled with Albacore 1.2.1+ or Guppy 2.1.3+ (Leger & Leonardi, 2019). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "echo 'Running pycoQC ...'\n",
    "\n",
    "pycoQC -f $SEQ_SUMMARY -o $RES/pycoqc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Convert basecalled fastqs.gz into one .qz file ...'\n",
    "\n",
    "gunzip -c $FASTQs/*.gz | gzip > $RES/reads.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Low-quality reads with nanofilt\n",
    "\n",
    "[Nanofilt](https://github.com/wdecoster/nanofilt) is a tool written for Python 3 but executable in bash. It performs filtering on quality and/or read length, and optional trimming after passing filters (De Coster et al., 2018).\n",
    "Intended to be used:\n",
    "\n",
    " - directly after fastq extraction\n",
    " - prior to mapping\n",
    " - in a stream between extraction and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install nanofilt\n",
    "#conda\n",
    "conda install -c bioconda nanofilt\n",
    "#pip\n",
    "pip install nanofilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This below runs Nanofilt, trimming quality at <int>7> (based on pycoQc analysis).\n",
    "#Remember a quality of 10 indicates 90% accuracy.\n",
    "gunzip -c reads.fastq.gz | NanoFilt -q 10 | gzip > highQuality-reads.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adapter and Quality Trimming with Porechop\n",
    "\n",
    "[Porechop](https://github.com/rrwick/Porechop) is a tool for finding and removing adapters from Oxford Nanopore reads. Adapters on the ends of reads are trimmed off, and when a read has an adapter in its middle, it is treated as chimeric and chopped into separate reads. Porechop performs thorough alignments to effectively find adapters, even at low sequence identity (Wick et al., 2017).\n",
    "\n",
    "Begin by cloning the repo (below). Running the setup.py script will compile the C++ components of Porechop and install a porechop executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone the repo\n",
    "git clone https://github.com/rrwick/Porechop.git\n",
    "# move to the porechop working directory\n",
    "cd Porechop\n",
    "#Run the script setup.py to compile and install porechop\n",
    "python3 setup.py install\n",
    "#Check whether porechop has been successfully installed, as well as how its used\n",
    "porechop -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic adapter trimming can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "porechop -i $fastq_dir -o output_reads.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NanoPlot\n",
    "\n",
    "[Nanoplot](https://github.com/wdecoster/NanoPlot) is also a plotting tool for long read sequencing data and alignments (De Coster et al., 2018). It takes more input formats than pycoQC including multiple `.fastq files`. Once your reads have been trimmed and filtered NanoPlot can be run using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%shell\n",
    "NanoPlot -t 20 --fastq $RES/adfree_reads.fastq.gz --N50 -o $RES \\\n",
    "--maxlength 40000 --plots dot --legacy hex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Reference Genome for mapping.\n",
    "Our data is sourced from the Black Soldier Fly (BSF). The BSF reference genome can be found [here](https://www.ncbi.nlm.nih.gov/assembly/GCF_905115235.1/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _De novo_ Genome Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advances in DNA sequencing has enabled the rapid analysis of genomes, driving biological discovery. However, sequencing of complex genomes, which are very large and have a high content of repetitive sequences or many copies of similar sequences, still remains a great challenge. With improvements in long-read sequencing however, it is easier to generate high-quality sequences for complex genomes. The **Overlap Layout Consensus algorithm (OLC)** is best suited for long-read sequencing technologies like [PacBio](https://www.pacb.com/smrt-science/smrt-sequencing/) and [ONT](https://nanoporetech.com/applications/dna-nanopore-sequencing).\n",
    "\n",
    "TGS generate read lengths of over 10,000 base-pairs that can be advantageously used to improve the genome assembly.Long reads can span stretches of repetitive regions and thus produce a more\n",
    "contiguous reconstruction of the genome.\n",
    "\n",
    "There are two main families of assemblers based on long reads:\n",
    "1. Long Reads Only assembler (LRO)\n",
    "1. Short and Long Reads combined assembler (SLR)\n",
    "\n",
    "LRO assemblers are based on the OLC algorithm. SLR assemblers instead generate a de Bruijn graph pre-assembly using short reads, then the long reads are used to improve the pre-assembly by closing gaps, ordering contigs, and resolving repetitive regions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLC\n",
    "\n",
    "![](https://www.researchgate.net/profile/Christina-Toft/publication/26266221/figure/fig2/AS:216492458156039@1428627232413/Overlap-layout-consensus-genome-assembly-algorithm-Reads-are-provided-to-the-algorithm.png)\n",
    "\n",
    "\n",
    "Resource: [Long-read tools](https://long-read-tools.org/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "* [minimap2](https://github.com/lh3/minimap2): All-vs-all overlap\n",
    "* [Miniasm](https://github.com/lh3/miniasm): Layout \n",
    "* [Minipolish](https://github.com/rrwick/Minipolish): Consenus\n",
    "\n",
    "* [QUAST](http://quast.sourceforge.net/docs/manual.html): Quality Assesment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We will use the [African Swine Fever Virus (ASFV)](https://mra.asm.org/content/9/44/e00948-20) genome which is double stranded with a size of 170 to 194 kbp. Data used was from a Virulent African Swine Fever Virus from a Domestic Pig in Ukraine under the SRA accession number [SRX6477592](https://www.ncbi.nlm.nih.gov/sra/SRX6477592[accn]). The preprocess step involved mapping the reads to the Sus scrofa 11 reference genome [GCA_000003025](https://www.ncbi.nlm.nih.gov/assembly/?term=GCF_000003025) to remove reads likely originating from the host. [minimap2](https://github.com/lh3/minimap2) map long noisy genomic reads will be used at this step. The SAM output was converted to BAM using [Samtools](http://www.htslib.org/). Umapped reads will be  filtered out using samtools and converted to fastq format. [Porechop](https://github.com/rrwick/Porechop) was used to trim adaptors discard and sequences with middle adapters. The chopped unmapped fastq reads will be used as the input in the pipeline.\n",
    "\n",
    "Script for the preprocess step:\n",
    "\n",
    "\n",
    "``` sh\n",
    "#!/usr/bin/env bash\n",
    "#SBATCH -p batch\n",
    "#SBATCH -J Mini_PK\n",
    "#SBATCH -n 16\n",
    "\n",
    "#load the minimap2 module\n",
    "\n",
    "\n",
    "module load minimap2/2.13\n",
    "\n",
    "\n",
    "#run the minimap2 with 16 CPU threads (cores)\n",
    "\n",
    "#mapping the Ukranian reads on the ref genome\n",
    "\n",
    "\n",
    "minimap2 -ax map-ont /home/pkimani/Data/Sus_scrofa/GCF_000003025.6_Sscrofa11.1_genomic.fna /home/pkimani/Data/Ukraine/SRR9719895.fastq.gz > /home/pkimani/Data/Ukraine/SRR9719895.sam\n",
    "\n",
    "\n",
    "#converting sam to bam\n",
    "\n",
    "module load samtools/1.11\n",
    "\n",
    "samtools view -O BAM /home/pkimani/Data/Ukraine/SRR9719895.sam -o /home/pkimani/Data/Ukraine/SRR9719895.bam\n",
    "\n",
    "\n",
    "#filter unmapped reads\n",
    "\n",
    "samtools view -b -f 4  /home/pkimani/Data/Ukraine/SRR9719895.bam >  /home/pkimani/Data/Ukraine/SRR9719895.unmapped.bam\n",
    "\n",
    "\n",
    "#extract the fastq sequence\n",
    "\n",
    "samtools fastq -0  /home/pkimani/Data/Ukraine/SRR9719895.unmapped.fastq /home/pkimani/Data/Ukraine/SRR9719895.unmapped.\n",
    "\n",
    "\n",
    "#zip\n",
    "gzip  /home/pkimani/Data/Ukraine/SRR9719895.unmapped.fastq \n",
    "\n",
    "# trim adapters\n",
    "module load porechop/0.2.4\n",
    "\n",
    "porechop -i /home/pkimani/Data/Ukraine/SRR9719895.unmapped.fastq.gz -o /home/pkimani/Data/Ukraine/SRR9719895.unmapped.chopped.fastq  --discard_middle\n",
    "\n",
    "```\n",
    "\n",
    "#### Processed dataset\n",
    "\n",
    "Download the processed dataset [here](https://drive.google.com/file/d/1g4g1RNo40LWZx6oRebgVMjGdwR4qSd3K/view?usp=sharing) \n",
    "\n",
    "#### Reference genome\n",
    "\n",
    "We will use the [reference genome](https://www.ncbi.nlm.nih.gov/nuccore/MN194591) from a Ukranian study with a length 191,911 bp to assess the quality of our assembly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap \n",
    "\n",
    "```sh\n",
    "minimap2 -x ava-ont SRR9719895.unmapped.choped.fastq.gz SRR9719895.unmapped.choped.fastq.gz > SRR9719895.paf\n",
    "```\n",
    "\n",
    "#### Layout\n",
    "\n",
    "```sh\n",
    "miniasm -f  SRR9719895.unmapped.choped.fastq.gz SRR9719895.paf > SRR9719895.gfa\n",
    "```\n",
    "\n",
    "#### Concensus\n",
    "\n",
    "```sh\n",
    "minipolish  SRR9719895.unmapped.choped.fastq.gz SRR9719895.gfa  >SRR9719895_polished.gfa\n",
    "```\n",
    "\n",
    "#### convert gfa to fasta\n",
    "```sh\n",
    "awk '$1 ~/S/ {print \">\"$2\"\\n\"$3}' SRR9719895_polished.gfa > SRR9719895_polished.fasta\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "#!/bin/bash\n",
    "\n",
    "#catch errors\n",
    "set -eu\n",
    "\n",
    "#read in the fastq file for mapping\n",
    "read -p \"Enter a path to the fastq file: \" file\n",
    "\n",
    "#check if the file exists or is empty\n",
    "\n",
    "if [[ ! -e ${file} ]]\n",
    "then \n",
    "\techo \"file does not exist\"\n",
    "\n",
    "elif [[ ! -s ${file} ]]\n",
    "then\n",
    "\techo \"file is empty\"\n",
    "\n",
    "else\n",
    "\techo \"file is in the right format\"\n",
    "\techo \"Proceeding\"\n",
    "\n",
    "fi\n",
    "\n",
    "output=\"output.paf\"\n",
    "\n",
    "echo \" initiating assembly\"\n",
    "\n",
    "echo \" Keep calm\"\n",
    "\n",
    "minimap2 -x ava-ont ${file} ${file} >  ${output}\n",
    "\n",
    "echo \" All-vs-All overlap complete\"\n",
    "\n",
    "echo \" Initiating the miniasm\"\n",
    "\n",
    "output2=\"output.gfa\"\n",
    "\n",
    "miniasm -f ${file} ${output} > ${output2}\n",
    "\n",
    "echo \"Graph assembly complete\"\n",
    "\n",
    "echo \"initiating the consensus step\"\n",
    "\n",
    "minipolish ${file} ${output2} > polished.gfa\n",
    "\n",
    "#converts the gfa format to fasta format\n",
    "\n",
    "awk '$1 ~/S/ {print \">\"$2\"\\n\"$3}' polished.gfa > polished.fasta\n",
    "\n",
    "echo \" Successfully assembled\" \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality Assesment using QUAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "quast -o Quast -r {ref} SRR9719895_polished.fasta\n",
    "```\n",
    "\n",
    "[Results](file:///home/muchina/Genome_Assemblers/Assembly/Ukraine_repo/Quast_3/report.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant calling and annotation of ONT alignment data\n",
    "\n",
    "\n",
    "### Generate a .vcf file using Freebayes\n",
    "**Freebayes** is a Bayesian genetic variant detector designed to find small polymorphisms, specifically SNPs (single-nucleotide polymorphisms), indels (insertions and deletions), MNPs (multi-nucleotide polymorphisms), and complex events (composite insertion and substitution events) smaller than the length of a short-read sequencing alignment (Garrison & Marth, 2012).\n",
    "\n",
    "We are going to use [this](https://drive.google.com/file/d/1rVZKC4vD_a3ZxrjIu_BVaE8807_RZu5B/view?usp=sharing) bam file to generate a `.vcf` file.\n",
    "\n",
    "#### Installing freebayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c bioconda freebayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running freebayes using .bam input\n",
    "\n",
    "We are going to generate a .vcf file which we will later annotate using a .bam alignment file of the Black soldier Fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freebayes -f genomic/ref.fa aln.bam >var.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant Annotation using snpEff\n",
    "[**SnpEff**](http://pcingola.github.io/SnpEff/se_introduction/) is a variant annotation and effect prediction tool. It annotates and predicts the effects of genetic variants (such as amino acid changes).Genetic variants refer to differences between a genome and a \"reference\" genome. \n",
    "\n",
    "\n",
    "A typical snpEff operation use case is as follows:\n",
    "\n",
    "\n",
    "**Input**: The inputs are predicted variants (SNPs, insertions, deletions and MNPs). The input file is usually obtained as a result of a sequencing experiment, and it is usually in variant call format (VCF).\n",
    "\n",
    "\n",
    "**Output**: SnpEff analyzes the input variants. It annotates the variants and calculates the effects they produce on known genes (e.g. amino acid changes). \n",
    "\n",
    "The conda installation of snpEff is not very reliable. To install snpEff, run the following command then unzip the file:\n",
    "\n",
    "`wget https://snpeff.blob.core.windows.net/versions/snpEff_latest_core.zip` \n",
    "\n",
    "The first step involves checking whether your genome exists in the snpEff database. Remember, snpEff is made using java, and to run it, you must either specify the full location of the `.jar` file, or run snpEff in the same directory as the `.jar` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Check whether snpEff is successfully installed.\n",
    "java -jar snpEff.jar\n",
    "\n",
    "## Check whether the snpEff database contains the genome whose variants you are annotating\n",
    "## The .bam files are from Hermetia illucens, the Black soldier fly\n",
    "java -jar snpEff.jar databases | grep Hermetia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a snpEff database\n",
    "If your database is not present, you will have to build your own database. There are many ways to build a snpEff database mainly dependent on the input data. In our case, we are going to use the `genomic.fna.gz` file and the `.gff` file.\n",
    "\n",
    "To do this, do as follows:\n",
    "\n",
    "Go [here](https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/905/115/235/GCF_905115235.1_iHerIll2.2.curated.20191125/GCF_905115235.1_iHerIll2.2.curated.20191125_genomic.gff.gz) and download the `.gff` file, and [here](https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/905/115/235/GCF_905115235.1_iHerIll2.2.curated.20191125/GCF_905115235.1_iHerIll2.2.curated.20191125_genomic.fna.gz) to download the `genomic.fna.gz` if you had not downloaded it.\n",
    "\n",
    "Then follow the following steps:\n",
    "\n",
    "**i. Edit the config file and add the prefix to your genome**. \n",
    "   \n",
    "In order to tell SnpEff that there is a new genome available, you must update SnpEff's configuration file snpEff.config. The config file is present in the snpEff folder. Move to the end of the config file and add the genome prefix and its name. \n",
    "   In our case:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Edit the snpEff.config file and add the prefix to your genome. Add this as the last line of the file:\n",
    "GCF_905115235.1.genome : Hermetia illucens, complete genome\n",
    "\n",
    "### Create a directory for the new genome\n",
    "cd /path/to/snpEff/data/\n",
    "mkdir GCF_905115235.1\n",
    "\n",
    "## Get the .gff file using wget, or if you have it downloaded mv it to the data folder.\n",
    "mv /path/to/gff.gz .\n",
    "## Rename the gff.gz to genes.gff.gz\n",
    "mv gff.gz to genes.gff.gz\n",
    "\n",
    "\n",
    "## Get the genome using wget, or if you have it downloaded, move it to the data folder into a new folder called genomes\n",
    "mv /path/to/genomic.fna.gz ./genomes\n",
    "## Rename the genome to the prefix in the config file only\n",
    "mv GCF_905115235.1_iHerIll2.2.curated.20191125_genomic.fna.gz to GCF_905115235.1.gz\n",
    "\n",
    "\n",
    "###Run the build command as follows:\n",
    "java -jar snpEff.jar build -gff3 -v GCF_905115235.1\n",
    "\n",
    "### Annotate the variants\n",
    "java -Xmx8g -jar snpEff.jar GCF_905115235.1 var.vcf > annotated.vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the output.\n",
    "The `snpEff`  program performs some statistics and saves them to the file `snpEff_summary.html` on the directory where snpEff is being executed which canbe visualized on your browser.\n",
    "SnpEff also generates a TXT (tab separated) file having counts of number of variants affecting each transcript and gene. By default, the file name is `snpEff_genes.txt`(Cingolani et al., 2012)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. De Coster, W., D’Hert, S., Schultz, D. T., Cruts, M., & Van Broeckhoven, C. (2018). NanoPack: visualizing and processing long-read sequencing data. Bioinformatics, 34(15), 2666–2669. https://doi.org/10.1093/BIOINFORMATICS/BTY149\n",
    "\n",
    "\n",
    "2. Leger, A., & Leonardi, T. (2019). pycoQC, interactive quality control for Oxford Nanopore Sequencing. Journal of Open Source Software, 4(34), 1236. https://doi.org/10.21105/JOSS.01236\n",
    "\n",
    "\n",
    "3. Payne, A., Holmes, N., Rakyan, V., & Loose, M. (2019). BulkVis: a graphical viewer for Oxford nanopore bulk FAST5 files. Bioinformatics, 35(13), 2193–2198. https://doi.org/10.1093/BIOINFORMATICS/BTY841\n",
    "\n",
    "\n",
    "4. Wick, R. R., Judd, L. M., Gorrie, C. L., & Holt, K. E. (2017). Completing bacterial genome assemblies with multiplex MinION sequencing. Microbial Genomics, 3(10), e000132. https://doi.org/10.1099/MGEN.0.000132\n",
    "\n",
    "\n",
    "5. Victoria, D. D. A., Erik, H., Lieven, S., Salvadors, C. G., Cederic, N., Olga, V. P., ... & Henrik, L. (2018). Ten steps to get started in Genome Assembly and Annotation. F1000Research \n",
    "\n",
    "\n",
    "6. Cingolani, P., Platts, A., Wang, L. L., Coon, M., Nguyen, T., Wang, L., Land, S. J., Lu, X., & Ruden, D. M. (2012). A program for annotating and predicting the effects of single nucleotide polymorphisms, SnpEff. Fly, 6(2), 80–92. https://doi.org/10.4161/fly.19695\n",
    "\n",
    "\n",
    "7. Garrison, E., & Marth, G. (2012). Haplotype-based variant detection from short-read sequencing. https://arxiv.org/abs/1207.3907v2\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
